<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[KeepAlive安装以及简单配置]]></title>
    <url>%2F2020%2F01%2F02%2FKeepAlive%E5%AE%89%E8%A3%85%E4%BB%A5%E5%8F%8A%E7%AE%80%E5%8D%95%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[操作系统：Centos7.3 一.依赖安装首先安装相关依赖： 123yum install -y gcc openssl-devel popt-develyum -y install libnl libnl-develyum install -y libnfnetlink-devel 基本依赖就安装完毕了，如果还缺少什么依赖在下一步编译的时候会有warning，百度去解决就好了 二.编译安装源码首先下载源码到指定目录: 12cd /usr/local/srcwget http://www.keepalived.org/software/keepalived-1.3.4.tar.gz 然后解压，配置 123tar zxvf keepalived-1.3.4.tar.gz cd keepalived-1.3.4./configure --prefix=/usr/local/keepalived 之后编译 12make make install 注意这一步make之后可能会有warning，一般都是缺少依赖造成的，把warning关键字百度一下去yum安装对应依赖就可以了 三.修改配置文件地址安装完成后，keepalived的默认配置文件地址和我们安装的地址不一样，所以cp过去就可以了 12345cp ../keepalived-1.3.4/keepalived/etc/init.d/keepalived /etc/init.d/mkdir /etc/keepalivedcp /usr/local/keepalived/etc/keepalived/keepalived.conf /etc/keepalived/cp keepalived-1.3.4/keepalived/etc/sysconfig/keepalived /etc/sysconfig/cp /usr/local/keepalived/sbin/keepalived /usr/sbin/ 之后只要修改/etc/keepalived/ 目录下的keepalived.conf配置文件就可以了 使用service start keepalived启动服务 四.附keepalived简单配置文件1234567891011121314151617181920! Configuration File for keepalivedglobal_defs &#123; router_id lb01 #设置本机路由id，做区分的&#125;vrrp_instance VI_1 &#123; state MASTER #主从标记，仅做标识 interface eth0 #虚拟路由的网卡名 virtual_router_id 51 #虚拟路由路由id，想要配置在同一个虚拟ip必须要有相同id priority 150 #优先级，优先级最高的自动为主机，主机宕机后按照优先级选择热备从机 advert_int 1 #主备通讯时间间隔 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 172.17.0.199 #配置到哪个虚拟ip，这里我是在docker中，所以是这个docker的默认网段的一个ip，主备机这个地方ip要相同 &#125;&#125;]]></content>
      <categories>
        <category>分布式系统</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>运维相关</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot WebSocket技术]]></title>
    <url>%2F2019%2F12%2F31%2FSpring%20Boot%20WebSocket%E6%8A%80%E6%9C%AF%2F</url>
    <content type="text"><![CDATA[最近看了Spring in Action，了解了一下WebSocket和Stomp协议相关技术，并搭建了一个项目。网上的例子不完整或者描述不清，所以自己记录一下以作备忘。 一.配置&#160; &#160; &#160; &#160;Spring Boot项目搭建完成后，基于Spring Boot一切皆配置的概念，添加WebSocket支持十分简单。 &#160; &#160; &#160; &#160;首先是maven依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-websocket&lt;/artifactId&gt;&lt;/dependency&gt; &#160; &#160; &#160; &#160;如果是使用的Spring Mvc的话，可能需要添加另外的2个依赖。 &#160; &#160; &#160; &#160;然后是添加配置类：WebSocketConfig 12345678910111213141516171819import org.springframework.context.annotation.Configuration;import org.springframework.messaging.simp.config.MessageBrokerRegistry;import org.springframework.web.socket.config.annotation.AbstractWebSocketMessageBrokerConfigurer;import org.springframework.web.socket.config.annotation.EnableWebSocketMessageBroker;import org.springframework.web.socket.config.annotation.StompEndpointRegistry;@Configuration@EnableWebSocketMessageBrokerpublic class WebSocketConfig extends AbstractWebSocketMessageBrokerConfigurer &#123; @Override public void registerStompEndpoints(StompEndpointRegistry stompEndpointRegistry) &#123; stompEndpointRegistry.addEndpoint("/endpointSang").withSockJS(); &#125; @Override public void configureMessageBroker(MessageBrokerRegistry registry) &#123; registry.enableSimpleBroker("/happy"); &#125;&#125; 其中的两个路径：1.addEndpoint添加的第一个路径，是监听WebSocket连接的Stomp代理的端点，页面请求WebSocket连接时，连接到注册的该端点上Stomp代理，之后的消息会交给Stomp代理处理。 2.该配置启用了一个简单的消息代理，用来处理前缀为/happy的消息，也就是说，只有路径为/happy请求时，消息才会由消息代理处理 二.后端配置控制器ControllerController十分相似，部分注解略有不同: 123456789101112131415161718192021222324252627282930import com.example.demo.bean.TestMessage;import com.example.demo.bean.TestResponse;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.messaging.handler.annotation.MessageMapping;import org.springframework.messaging.handler.annotation.SendTo;import org.springframework.messaging.simp.SimpMessagingTemplate;import org.springframework.stereotype.Controller;import java.text.DateFormat;import java.text.SimpleDateFormat;import java.util.Date;@Controllerpublic class WsController &#123; @Autowired private SimpMessagingTemplate messagingTemplate; @MessageMapping("/welcome")//接收路径 @SendTo("/happy/getNewResponse")//消息返回到的路径 public TestResponse say(TestMessage message) &#123; System.out.println(message.getName()); say1();//调用另外的方式返回（由服务器主动发起的返回） return new TestResponse("welcome," + message.getName() + " !");//这次同步通信的返回 &#125; public void say1() &#123; Date date =new Date(System.currentTimeMillis()); DateFormat df = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss"); System.out.println(date); messagingTemplate.convertAndSend("/happy/getHappyResponse", df.format(new Date()));//设置路径以及内容，返回当前服务器时间 &#125;&#125; TestMessage与TestResponse为普通JavaBean，消息转换机制等与普通Controller基本一致 SimpMessagingTemplate该类提供为主动向页面正在监听WebSocket的程序发送消息的功能 @MessageMapping注解，与@RequestMapping注解类似，配置后台接收消息的路径以及处理函数 @SendTo注解，一般与@MessageMapping注解一起使用，该注解配置的控制器，返回的数据将发送到监听该配置路径的监听函数 三.前端页面123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566&lt;html lang="en" xmlns:th="http://www.thymeleaf.org"&gt;&lt;head&gt; &lt;meta charset="UTF-8"/&gt; &lt;title&gt;广播式WebSocket&lt;/title&gt; &lt;script src="../static/jquery.min.js"&gt;&lt;/script&gt; &lt;script src="../static/stomp.js"&gt;&lt;/script&gt; &lt;script src="../static/sockjs.js"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body onload="disconnect()"&gt;&lt;div&gt; &lt;div&gt; &lt;button id="connect" onclick="connect();"&gt;连接&lt;/button&gt; &lt;button id="disconnect" disabled="disabled" onclick="disconnect();"&gt;断开连接&lt;/button&gt; &lt;/div&gt; &lt;div id="conversationDiv"&gt; &lt;label&gt;输入你的名字&lt;/label&gt;&lt;input type="text" id="name"/&gt; &lt;button id="sendName" onclick="sendName();"&gt;发送&lt;/button&gt; &lt;p id="response"&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;script type="text/javascript"&gt; var stompClient = null; function setConnected(connected) &#123; document.getElementById("connect").disabled = connected; document.getElementById("disconnect").disabled = !connected; document.getElementById("conversationDiv").style.visibility = connected ? 'visible' : 'hidden'; $("#response").html(); &#125; function connect() &#123; var socket = new SockJS('/endpointSang');//通过先前配置的端点建立连接 stompClient = Stomp.over(socket); stompClient.connect(&#123;&#125;, function (frame) &#123; setConnected(true); console.log('Connected:' + frame); //开启监听，监听服务器推送到路径/happy/getNewResponse stompClient.subscribe('/happy/getNewResponse', function (response) &#123; alert(JSON.parse(response.body).responseMessage); &#125;); //开启监听，监听服务器推送到路径/happy/getHappyResponse stompClient.subscribe('/happy/getHappyResponse', function (response) &#123; console.log(response.body); &#125;) &#125;); &#125; //关闭连接 function disconnect() &#123; if (stompClient != null) &#123; stompClient.disconnect(); &#125; setConnected(false); console.log('Disconnected'); &#125; //主动发送信息 function sendName() &#123; var name = $('#name').val(); console.log('name:' + name); //发送信息到后台监听/welcome路径的controller stompClient.send("/welcome", &#123;&#125;, JSON.stringify(&#123;'name': name&#125;)); &#125; function showResponse(message) &#123; $("#response").html(message); &#125;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 运行结果控制台日志： 注：广播模式，只要所有程序监听同一个后台广播路径就可以了点对点通信模式，可以在Js端使用随机数或者根据TokenId开启监听路径，后台根据用户的TokenId派发到不同端点就可以了]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>WebSocket</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[xxl-job较深入使用]]></title>
    <url>%2F2019%2F12%2F31%2Fxxl-job%E8%BE%83%E6%B7%B1%E5%85%A5%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[&#160; &#160; &#160; &#160;xxl-job是一个分布式定时任务调度框架，功能强大，底层使用自己实现的rpc框架进行注册和管理，数据库使用mysql，调度触发使用数据库锁来作为调度锁。 &#160; &#160; &#160; &#160;xxl-job主要分为调度中心admin以及任务，任务引入依赖jar包并配置启动类为spring所管理的bean后，将自动通过spring-bean提供的initMethod进行启动线程选择一个端口进行注册以及监听任务调度。 &#160; &#160; &#160; &#160;公司目前引入xxl-job框架代替quartz框架作为分布式任务调度组件，并在其之上进行一定开发以及优化，所以这篇文章主要分享一些深入使用，主要是概念的详细介绍。 系统关键概念介绍执行器&#160; &#160; &#160; &#160;配置中心配置的执行器，概念上对应执行定时任务的服务，支持分布式调度以及调度的各种路由规则配置。注册方式支持自动注册和手动配置机器地址两种方式，心跳时间间隔默认为30s，失效时间90s。 &#160; &#160; &#160; &#160;执行器自动注册后，调度中心页面依旧有最长30秒的延迟显示，原因是数据库中注册表更新后，展示执行器的表是由另一个守护线程去更新的，更新频率为默认心跳时间30s，所以管理台展示会有延迟，但不影响任务调度。 任务&#160; &#160; &#160; &#160;任务以执行器为维度配置，每个任务必须属于一个执行器，当任务触发时会根据该任务所属的执行器去寻找执行器的地址列表，然后通过配置的路由规则以及阻塞规则去去执行。 &#160; &#160; &#160; &#160;任务支持本地任务以及远程任务，本地任务即按照执行方写好的业务逻辑执行。远程任务通过GLUE，在调度中心管理台写好代码，分发到执行方去执行。建议无特殊需求的话，统一使用本地任务。 任务配置项描述1. 执行器：选择该任务由哪个执行器去执行2. 任务描述：简单描述该任务的功能以及作用，如：码上行单边行程推送3. 路由策略：设置任务执行时，如何去选择执行器，高频任务建议使用一致性哈希或者第一台执行4. Cron：Cron表达式，描述任务运行的时间5. 运行模式：BEAN即为接入服务配置在本地对应的handler运行，其他方式均为管理台设置代码交由接入服务远程执行6. JobHandler：运行模式为BEAN时必填，值应当为接入服务本地执行任务的handler7. 阻塞策略：当同一任务多次调度到同一台执行器时，执行器应当使用的策略8. 子任务ID：如配置，则该任务完成后自动触发一次子任务的执行9. 任务超时时间：配置后当任务超时时将自动终止任务执行。10. 失败重试次数：任务失败后重试的次数。11. 负责人：一般为该任务接入方的负责人12. 报警邮件：任务报警后发送的邮件地址13. 任务参数：若配置了任务参数，任务调度时将发送任务参数至执行方handler。 阻塞策略&#160; &#160; &#160; &#160;阻塞策略即同一个任务在执行器的阻塞执行策略。由执行器端控制。典型场景为：任务A分发到执行器A执行，此时任务A再次触发并分发到执行器A，此时根据阻塞策略选择的不同将会有以下三种执行策略：1. 单机串行 该策略下，同一执行器收到同一任务的调度触发时，若已有任务正在执行，会将后续的任务放入执行线程的队列中，等待线程轮询继续执行，可能会导致线程队列阻塞过多任务导致内存过高，高频且耗时较长任务慎用。 2. 丢弃后续调度 该策略下，同一执行器收到同一任务的调度触发时，若已有任务正在执行，会直接丢弃后续同一任务的调度，推荐使用。 3. 3. 覆盖之前调度 该策略下，同一执行器收到同一任务的调度触发时，若已有任务正在执行，将会直接停止正在执行的任务（通过线程InterruptedException异常以及volatile变量判断），并将新任务放入队列。一般情况下不建议使用。 路由策略&#160; &#160; &#160; &#160;路由策略即任务在配置中心进行调度分发时，选择执行器的策略。由配置中心端控制。典型场景为：任务A触发执行，任务A对应的执行器有执行器A，B，C，D，此时根据路由策略的选择将会有以下几种分发情况1. 第一个：始终选择第一台执行器作为任务执行器，不论该任务执行器是否正常。2. 最后一个：始终选择最后一台作为任务执行器3. 轮询：每个执行器轮流执行4. 随机：随机选择一个执行器执行5. 一致性HASH：根据任务ID做一致性哈希选择执行器，同一个任务必定只分发到同一个执行器。高频或耗时较长任务推荐使用6. 最不经常使用：选择平均使用频率最低的执行器。7. 最近最久未使用：选择最近的最久未使用的执行器。8. 故障转移：分别进行心跳检测，选择第一台心跳检测正常的机器执行。9. 忙碌转移：分别进行忙碌检测，选择第一台空闲的机器执行。10. 分片广播：广播到所有执行器执行，并提供分片参数，分片参数获取方式如下，应用在被触发时动态获取自己是第几个分片，共有几个分片： 日志问题&#160; &#160; &#160; &#160;xxl-job相关日志使用默认使用slf4j作为日志框架，使用专门的API写入日志时，会输出2种日志，客户端日志与服务端日志 客户端日志&#160; &#160; &#160; &#160;客户端日志根据配置文件中配置的logpath指定，根据源码分析，客户端日志将通过FileOutputStream写到对应文件，且无法通过配置修改，所以只好修改了源码中的逻辑，改为该值为空未配置时，直接通过slf4j写入。 服务端日志&#160; &#160; &#160; &#160;使用xxljob的日志api输出日志时，日志也会在调度管理台看到，能看到的原理是xxl-job管理台会通过rpc调用执行器的接口，执行器收到请求后从指定的日志文件中读取执行的日志并返回，这里存在一个比较麻烦的问题，就是xxl-job这种日志的逻辑，无法很好的兼容到项目统一的日志模块里，十分不便。 &#160; &#160; &#160; &#160;所以实际使用过程中，我们在xxl-job管理台查询日志时，对其进行了改造，修改为不从rpc查询，而是走我们日志管理的搜索引擎根据执行的jobid查询相关日志，结合客户端日志输出的改造，从而统一xxl-job和我们系统间的日志管理。]]></content>
      <categories>
        <category>分布式系统</category>
      </categories>
      <tags>
        <tag>xxl-job</tag>
        <tag>定时任务调度</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot Scheduled定时任务特性]]></title>
    <url>%2F2019%2F07%2F03%2FSpring-Boot-Scheduled%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E7%89%B9%E6%80%A7%2F</url>
    <content type="text"><![CDATA[&#160; &#160; &#160; &#160;SpringBoot中的Scheduled定时任务是Spring Boot中非常常用的特性，用来执行一些比如日切或者日终对账这种定时任务 &#160; &#160; &#160; &#160;下面说说使用时要注意的Scheduled的几个特性 Scheduled的执行方式&#160; &#160; &#160; &#160;Scheduled按照顺序执行，对于某个task未做配置的话只会起一个线程去执行，也就是说当你某个任务在处理中阻塞了，哪怕轮询时间再次到达，Spring也不会再起线程执行该任务，而是会等待上次任务执行完毕，所以请不要在Scheduled的task中做一些比较需要频繁触发的易失败，易阻塞，易超时操作，避免任务无法正常轮询执行 Scheduled中的线程池&#160; &#160; &#160; &#160;Scheduled执行可以通过Spring Boot提供的配置来配置定时任务执行的线程池等信息，如果未做配置的话，根据我测试，所有定时任务仅有一个线程去执行，也就是说如果某个task阻塞，其他task都将得不到执行。具体配置方法如下 @Configuration @EnableScheduling public class SchedulerTaskConfiguration implements SchedulingConfigurer { @Override public void configureTasks(ScheduledTaskRegistrar scheduledTaskRegistrar) { scheduledTaskRegistrar.setScheduler(taskExecutor()); } @Bean public Executor taskExecutor() { //线程池大小 return Executors.newScheduledThreadPool(10); } }&#160; &#160; &#160; &#160;但是哪怕是配置了线程池，也只是降低了多个task之间执行的影响，对于单个task来说，哪怕配置了线程池，依旧会因为上次执行的阻塞影响到下一次触发 Scheduled的执行频率&#160; &#160; &#160; &#160;Scheduled的执行频率可以由2种方式控制，一种为在@Scheduled中添加fixedRate属性，即@Scheduled(fixedRate = 10)，数字为执行的间隔毫秒，也就是多少毫秒执行一次 &#160; &#160; &#160; &#160;另一种为添加cron属性，属性值为cron表达式，可以通过cron表达式指定为具体某年某月某分某秒，也可以通过cron表达式指定为间隔几小时或几分钟执行一次,如@Scheduled(cron = “0 0 1 * * *”)]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>Scheduled</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[不继续使用CSDN的原因]]></title>
    <url>%2F2019%2F06%2F27%2F%E4%B8%8D%E7%BB%A7%E7%BB%AD%E4%BD%BF%E7%94%A8CSDN%E7%9A%84%E5%8E%9F%E5%9B%A0%2F</url>
    <content type="text"><![CDATA[&#160; &#160; &#160; &#160;一直了解到很多人选择Hexo搭建自己的博客，本来想在自己云服务器上搭一个的，后面了解到Github可以通过静态资源的映射免费搞，还挺方便的，但是因为懒，一直就在CSDN写写，毕竟从大学开始就在CSDN上各种查资料和学习。 &#160; &#160; &#160; &#160;或许什么事都会变质吧，最近在某度查一个DB2的问题，发现置顶的2条竟然就是CSDN的内容，但是点进去竟然是类似于站内搜索的页面，只列出了一些内容相关的，但是在某度的页面上显示确实关键字完全匹配，这顿时让我觉得十分恶心。 &#160; &#160; &#160; &#160;所以抽空自己搞了下Hexo，不过有点想吐槽下，基本就是照着别人的教程弄，这东西想搞明白还是得NodeJs和前端都比较了解的人才能看懂或者定制化，有点伤。 &#160; &#160; &#160; &#160;不过一顿操作后，写写文章是没什么问题了，以后就在这里写吧。 &#160; &#160; &#160; &#160;就这样。]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git使用详解]]></title>
    <url>%2F2019%2F06%2F27%2FGit%E4%BD%BF%E7%94%A8%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[&#160; &#160; &#160; &#160;之前公司要做技术分享，因为Git虽然看似简单，但是实际上是使用较多而且较为重要的一个工具，所以做了一下大概的总结。 &#160; &#160; &#160; &#160;因为新来的同事问了一个问题，紧急版本要拉hotfix分支修改，但是hotfix分支如何优雅的合并到各个分支上去呢？尤其是hotfix修改的位置比较敏感的情况下。 所以顺带也研究了一下这个问题 &#160; &#160; &#160; &#160;下面根据Git最关键的几个概念，穿插了Git几个命令实际做了什么 版本号&#160; &#160; &#160; &#160;Git本身有版本号的概念，版本号基于每次commit，查看最近的commit可以使用git log查看，查看所有历史版本可以使用git reflog查看所有本地commit的版本号，使用这两个命令可以查看到commit过的记录和commit时填写的信息，但是命令行内查看好像暂时不支持中文的commit信息显示。 仓库&#160; &#160; &#160; &#160;Git有2个仓库概念，一个是远端仓库，一个是本地仓库。在本地和远端之间同步的时候一定要谨慎 本地仓库&#160; &#160; &#160; &#160;实际上，在不使用fetch，pull，push，merge这几个命令的情况下，Git是仅使用本地仓库就可以完成版本管理的，主要的命令（或者说是操作）涉及到add，commit。 add操作用于将目录下的文件添加到Git的工作空间里去，同目录下未使用add命令添加过的文件，是不参与到git版本管理中去的，也就是说是独立于Git的。 commit操作用于提交修改，仅限于本地，用于提交每次修改，commit会产生一个commit id，这个id标识这次commit，在本地的话，实际上版本管理就是不断基于commit做的版本管理，假设commit过3次内容为A,B,C。C为最后commit的版本，此时想回退，只需要git reset commitid –hard 命令，就能把本地仓库回退到B或A的那次commit。 revert用于在某次commit之后，假设commit id为A，此时做了一系列修改，但未commit，此时revert会将所有修改取消，回归到commit id为A时的状态。 远程仓库&#160; &#160; &#160; &#160;实际上，远程仓库仅仅可以看做是一个代码的备份，是一个公共的备份，也就是说，在每次push后，你的本地仓库和远程仓库所有文件应该是一模一样的，通过push的话，会把本地的所有commit同步到远程仓库上去，也就是说，远程仓库的commit过程应该是每个人在本地commit的总和，但可能顺序不同。 &#160; &#160; &#160; &#160;对本地仓库来说，pull就等于同步远端仓库到本地仓库加merge，push就等于把本地仓库同步到远端仓库加merge。 &#160; &#160; &#160; &#160;Merge的本质，是将两个分支同步，实际上都是在本地merge。说一下这个过程，假设现在远端仓库版本为A，此时小g和小w同时从A上pull到了本地仓库将他们自己的本地仓库同步到了远端的版本A，此时他们的本地仓库我们假设为A1，A2，他们基于A1,A2做了自己的修改，并且同时修改了test.txt，然后都想提交到远端，第一个提交的人肯定可以提交成功，但是第二个提交的人必定会出现push失败，需要merge该文件，此时他在idea中merge了该文件确认自己改的才是对的，然后再push，此时就成功了。 &#160; &#160; &#160; &#160;解释一下，此时的merge实际过程是他处理了冲突之后，又进行了一次针对merge的commit，此次commit专门用来处理冲突并提交，具体体现在idea里你会发现，有的时候会让你选accept theirs,accept yours，你选了accept yours或者全部按照你本地来作为最终版本的文件，不需要commit，如果你选的是accept theirs或者merge的时候选择了远端的修改，那么你本地需要全部commit一次再提交，也就是说实际处理的merge是在本地确认了merge结果，这次commit和push实际idea是做了特殊处理的，带着merge的头，所以可以不会再次触发冲突，idea直接通过强制-force push到远端。 Bug修改，Hotfix&#160; &#160; &#160; &#160;之前考虑到生产环境修改，紧急bug修复，会基于生产环境分支创建一个hotfix分支，做修改完成后由prod分支合并hotfix分支，然后删除hotfix分支，但是这带来了一个问题，该hotfix分支难以合并到例如dev，test等分支，因为： 1.配置文件问题，从hotfix分支merge到dev分支，会导致dev等分支配置文件被覆盖，十分麻烦 2.版本管理问题，如果dev此时分支远远超前prod分支，那么此时将不可能合并hotfix的修改到dev上 可以通过git的stash功能解决这个问题。 &#160; &#160; &#160; &#160;stash和他的操作unstash的本质，是创建一个修改副本。他的应用场景和操作模式在于，有的时候本地做了一系列修改，但是忽然又要全部回到修改前的时候进行一下打包，此时要么从新从远端拉一个分支到本地，要么就直接copy一份项目到其他目录，然后这个目录下的revert掉，改完覆盖回来。 &#160; &#160; &#160; &#160;stash可以轻松解决，stash可以对当前所有的修改（具体提现到所有蓝色的文件）做一个备份，创建一个stash后，项目会自动回到当前commit id的状态（相当于revert），相当于对所有修改做了一个另外的保存，然后可以通过unstash可以把这些修改还原回来。 &#160; &#160; &#160; &#160;这样的话通过这个功能可以很轻松的解决这个问题，本地check出来hotfix分支之后，修改完毕不要先commit，先进行stash，然后unstash回来，再进行commit，push。完成后回到dev分支进行unstash同样进行一下更改，就把更改应用在dev分支上了。]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>Git</tag>
      </tags>
  </entry>
</search>
